{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl8KYNbUNhaz",
        "outputId": "e86741fa-902f-4c59-c80d-360fcaa64a33"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#%cd /content/drive/MyDrive/FOCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsTYVbV6Tfvr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import natsort\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from PIL import Image, ImageFilter\n",
        "from torchvision.utils import save_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCuhpCCozmFZ"
      },
      "outputs": [],
      "source": [
        "def extract_key(filename):\n",
        "    base = os.path.basename(filename)\n",
        "    name, _ = os.path.splitext(base)\n",
        "    # Normalize keys for both types\n",
        "    if name.startswith(\"f-\") and \"-sz1\" in name:\n",
        "        return name.replace(\"-sz1\", \"\")\n",
        "    elif name.startswith(\"sketch\"):\n",
        "        return name.replace(\"sketch\", \"image\").replace(\"png\", \"jpg\")\n",
        "    return name\n",
        "\n",
        "def load_matched_filenames(photo_dir, sketch_dir):\n",
        "    photo_files = [os.path.join(photo_dir, f) for f in os.listdir(photo_dir)]\n",
        "    sketch_files = [os.path.join(sketch_dir, f) for f in os.listdir(sketch_dir)]\n",
        "\n",
        "    photo_dict = {extract_key(f): f for f in photo_files}\n",
        "    sketch_dict = {extract_key(f): f for f in sketch_files}\n",
        "\n",
        "    common_keys = sorted(set(photo_dict.keys()) & set(sketch_dict.keys()))\n",
        "    matched_photos = [photo_dict[k] for k in common_keys]\n",
        "    matched_sketches = [sketch_dict[k] for k in common_keys]\n",
        "    return matched_photos, matched_sketches\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, photo_paths, sketch_paths, size=(256, 256)):\n",
        "        self.photo_paths = photo_paths\n",
        "        self.sketch_paths = sketch_paths\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor()\n",
        "            #transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.photo_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        photo = Image.open(self.photo_paths[idx]).convert('RGB')\n",
        "        sketch = Image.open(self.sketch_paths[idx]).convert('RGB')\n",
        "        return self.transform(sketch), self.transform(photo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liJktBhUZ3MV"
      },
      "outputs": [],
      "source": [
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "#generator network\n",
        "class GlobalGenerator(nn.Module):\n",
        "    def __init__(self, img_channels=3, ngf=64, num_blocks=9):\n",
        "        super(GlobalGenerator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, ngf, kernel_size=7, stride=1, padding=3),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            #downsampling:\n",
        "            nn.Conv2d(ngf, ngf*2, kernel_size=3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(ngf*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ngf*2, ngf*4, kernel_size=3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(ngf*4),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            *[ResnetBlock(ngf*4) for _ in range(num_blocks)],\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(ngf*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(ngf, img_channels, kernel_size=7, stride=1, padding=3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7dnLMJYUUaB",
        "outputId": "f39e7c2b-b2bb-4418-8012-75c2ea6b0a9d"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print('Device:', device)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/FOCE/Combined Dataset/trained models/g_model_final_v3.pth'\n",
        "\n",
        "model = GlobalGenerator()\n",
        "model.load_state_dict(torch.load(model_path))  # load the saved weights\n",
        "model.eval()  # set model to evaluation mode\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekMms8lNZ2kn"
      },
      "outputs": [],
      "source": [
        "photo_path = '/content/drive/MyDrive/FOCE/Combined Dataset/test/photo/'\n",
        "sketch_path = '/content/drive/MyDrive/FOCE/Combined Dataset/test/sketch/'\n",
        "# photo = load_filename(photo_path)\n",
        "# sketch = load_filename(sketch_path)\n",
        "photo, sketch = load_matched_filenames(photo_path, sketch_path)\n",
        "dataset = ImageDataset(photo, sketch)\n",
        "batch_size = 1\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=6, pin_memory=True, shuffle=False)\n",
        "\n",
        "\n",
        "def display_images(sketch, photo):\n",
        "    sketch = (sketch.cpu().numpy().transpose(1, 2, 0))\n",
        "    photo = (photo.cpu().numpy().transpose(1, 2, 0))\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    ax[0].imshow(sketch)\n",
        "    ax[0].set_title(\"Sketch\")\n",
        "    ax[0].axis(\"off\")\n",
        "\n",
        "    ax[1].imshow(photo)\n",
        "    ax[1].set_title(\"Real Photo\")\n",
        "    ax[1].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#for displaying the dataset:\n",
        "for i, (sketches, real_faces) in enumerate(dataloader):\n",
        "  display_images(sketches[0], real_faces[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6kDw7jbcOcM"
      },
      "outputs": [],
      "source": [
        "def generate_face(model, sketch_img, i):\n",
        "    generated_face = model(sketch_img)\n",
        "    generated_face = generated_face[0]\n",
        "\n",
        "    # save_image((generated_face + 1) / 2, f'/content/drive/MyDrive/FOCE/CUHK/Generated Faces/generated_face_{i}.png')\n",
        "    save_image((generated_face + 1) / 2, f'/content/drive/MyDrive/FOCE/Combined Dataset/test/Generated Faces/generated_face_{i}.png')\n",
        "\n",
        "    return generated_face.detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnV-sJYye6rW"
      },
      "outputs": [],
      "source": [
        "def display_images(sketch, photo):\n",
        "    # Remove batch dimension if present\n",
        "    if sketch.dim() == 4:\n",
        "        sketch = sketch.squeeze(0)\n",
        "    if photo.dim() == 4:\n",
        "        photo = photo.squeeze(0)\n",
        "\n",
        "    # Ensure it's in shape [C, H, W]\n",
        "    if sketch.shape[0] == 1:  # grayscale\n",
        "        sketch = sketch.expand(3, -1, -1)\n",
        "    if photo.shape[0] == 1:\n",
        "        photo = photo.expand(3, -1, -1)\n",
        "\n",
        "    # Convert to [H, W, C] and normalize to [0,1]\n",
        "    sketch = (sketch.cpu().numpy().transpose(1, 2, 0) + 1) / 2\n",
        "    photo = (photo.cpu().numpy().transpose(1, 2, 0))\n",
        "\n",
        "    photo = cv2.resize(photo, (200,250))\n",
        "    sketch = cv2.resize(sketch, (200, 250))\n",
        "    # Plot\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    axs[0].imshow(sketch)\n",
        "    axs[0].set_title('Generated Image')\n",
        "    axs[1].imshow(photo)\n",
        "    axs[1].set_title('Real Face')\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8JhpGUTdBKK"
      },
      "outputs": [],
      "source": [
        "photo_path = '/content/drive/MyDrive/FOCE/Combined Dataset/test/photo/'\n",
        "sketch_path = '/content/drive/MyDrive/FOCE/Combined Dataset/test/sketch/'\n",
        "# photo = load_filename(photo_path)\n",
        "# sketch = load_filename(sketch_path)\n",
        "photo, sketch = load_matched_filenames(photo_path, sketch_path)\n",
        "\n",
        "dataset = ImageDataset(photo, sketch)\n",
        "batch_size = 1\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=6, pin_memory=True, shuffle=False)\n",
        "\n",
        "\n",
        "for i, (sketch, real_face) in enumerate(dataloader):\n",
        "  generated_face = generate_face(model, sketch, i)\n",
        "  print(generated_face.shape)\n",
        "  display_images(generated_face, real_face)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c5iNx-bh0q0"
      },
      "outputs": [],
      "source": [
        "def save_images(sketch, photo, generated, output_dir, epoch):\n",
        "\n",
        "    # Remove batch dimension if present\n",
        "    if sketch.dim() == 4:\n",
        "        sketch = sketch.squeeze(0)\n",
        "    if photo.dim() == 4:\n",
        "        photo = photo.squeeze(0)\n",
        "\n",
        "    # Ensure it's in shape [C, H, W]\n",
        "    if sketch.shape[0] == 1:  # grayscale\n",
        "        sketch = sketch.expand(3, -1, -1)\n",
        "    if photo.shape[0] == 1:\n",
        "        photo = photo.expand(3, -1, -1)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Convert tensors (range [-1,1]) to image arrays in [0, 1]\n",
        "    sketch_np = ((sketch.permute(1, 2, 0).cpu().numpy()) + 1) / 2\n",
        "    photo_np = ((photo.permute(1, 2, 0).cpu().numpy()))\n",
        "    #generated_np = ((generated.permute(1, 2, 0).cpu().numpy()) + 1) / 2\n",
        "\n",
        "    # Convert arrays to PIL Images\n",
        "    sketch_img = Image.fromarray((sketch_np * 255).astype('uint8'))\n",
        "    photo_img = Image.fromarray((photo_np * 255).astype('uint8'))\n",
        "    #generated_img = Image.fromarray((generated_np * 255).astype('uint8'))\n",
        "\n",
        "    # Apply sharpening to the generated image using our new ImageSharpener class\n",
        "    # sharpener = ImageSharpener(radius=2, percent=150, threshold=3)\n",
        "    # generated_img_sharp = sharpener.sharpen(generated)\n",
        "\n",
        "\n",
        "    fig, axs = plt.subplots(1, 4, figsize=(8, 4))\n",
        "    axs[0].imshow(sketch_img)\n",
        "    axs[0].set_title('Sketch')\n",
        "    axs[1].imshow(photo_img)\n",
        "    axs[1].set_title('Real Face')\n",
        "    axs[2].imshow(generated)\n",
        "    axs[2].set_title('Generated')\n",
        "    # axs[3].imshow(generated_img_sharp)\n",
        "    # axs[3].set_title('Sharpened Generated')\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Save images\n",
        "    # generated_img_sharp.save(os.path.join(output_dir, f'generated_sharpened_epoch_{epoch}.png'))\n",
        "    generated.save(os.path.join(output_dir, f'generated_image_{epoch}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2O1k8SqiHvO"
      },
      "outputs": [],
      "source": [
        "# output_dir = '/content/drive/MyDrive/FOCE/CUHK/Enhanced Images'\n",
        "output_dir = '/content/drive/MyDrive/FOCE/Combined Dataset/test/Generated Faces'\n",
        "\n",
        "for i, (sketch, real_face) in enumerate(dataloader):\n",
        "  # generated = Image.open(f'/content/drive/MyDrive/FOCE/CUHK/Generated Faces/generated_face_{i}.png')\n",
        "  generated = Image.open(f'/content/drive/MyDrive/FOCE/Combined Dataset/test/Generated Faces/generated_face_{i}.png')\n",
        "  save_images(sketch, real_face, generated, output_dir, i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
